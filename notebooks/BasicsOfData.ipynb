{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77a23811-02e8-4150-b5cf-5e2687421923",
   "metadata": {},
   "source": [
    "# What is Statistics?\n",
    "\n",
    "Statistics is the study of the tools and methods that allow us to learn from data. It involves: \n",
    "\n",
    "1. Understanding new types of data and statistical methods for their analysis\n",
    "2. Understanding properties of statistical methods\n",
    "3. Development of new statistical methods\n",
    "\n",
    "## Historical Milestones\n",
    "\n",
    "1.  **Ancient Times**: It gave rise to data collection on populations, harvests, and natural calamities.\n",
    "2.  **18th Century**: It gave rise to probability theory as the study of randomness and variation.\n",
    "3.  **19th Century**: It gave birth to modern statistics via demographical studies and genetics.\n",
    "4.  **20th Century**: It led to significant advances in statistical theory and statistical learning with rise of computers.\n",
    "5.  **21st Century**: It has led to huge data stores (Big Data) and advanced applications of statistical methods on data (Machine Learning). \n",
    "\n",
    "\n",
    "## Statistic\n",
    "\n",
    "It is the numerical and graphical summary of a collection of data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb951862-c44c-43a2-8264-eff3ab5d0a85",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Study Design\n",
    "\n",
    "It refers to the different types of research studies that give rise to data. It is crucial for **power analysis** which is the process to assess whether a study design is likely to yield meaningful findings.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2853c0d-2574-4f4b-babb-cc8300cc074f",
   "metadata": {},
   "source": [
    "## Confirmatory vs Exploratory\n",
    "\n",
    "1. Confirmatory Studies employ the scientific method (Falsifiable Hypothesis -> Data Collection -> Testing Hypothesis Validity)\n",
    "\n",
    "2. Exploratory Studies collect and analyze data without pre-specifying question. \n",
    "\n",
    "While the latter is informative, it can be misleading. The more questions we ask from a dataset, the more likely we are to draw a misleading conclusion (multiple testing, p-hacking, overfitting). \n",
    "\n",
    "\n",
    "## Comparative vs Non-Comparative\n",
    "\n",
    "1. Comparative Studies compares a feature between two things. Eg: Harvest of Oranges in Spain vs Italy\n",
    "2. Non comparative Studies estimate the value of a feature. Eg: Stock Price prediction.\n",
    "\n",
    "\n",
    "## Observational vs Experimental\n",
    "\n",
    "1. Observational studies give rise to natural grouping of data. Eg: Lifespan of Smokers vs Non Smokers\n",
    "2. Experimental studies involve manipulation of different groups. Eg: Drug Trials\n",
    "\n",
    "The observational studies are often susceptible to bias where sample is not representative or measurements are systematically off-target."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4aa71f-8f5b-4e17-acee-4289137627df",
   "metadata": {},
   "source": [
    "# Data \n",
    "\n",
    "It can take on many forms: numbers, images, text, audio, etc. But where does data come from?\n",
    "\n",
    "1. **Organic/Process Data**: It refers to data that are generated as a result of a process (POS, Stock Market, Search History, etc). It often leads to Big Data that can be \"mined\" with statistical methods to study trends and relationships.\n",
    "2. **Designed Data**: It refers to data collected to address a specific research objective via sampling (Tweet Extraction, Census Survey). It is often smaller than organic data and do not reflect natural trends."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26732c1-8d47-4d7c-8a79-753ccac5f77f",
   "metadata": {},
   "source": [
    "## IID Data \n",
    "\n",
    "The data source has direct implications for an important consideration: **IID Data**. This refers to data being independent (each data point does not influence others) and identically distributed (all data points come from the same probability distribution). It is important because: \n",
    "\n",
    "1. Under independence assumptions, probabilities can be multiplied easily.\n",
    "2. Under identical distributions, we can summarize with a single statistic.\n",
    "3. Many statistical methods can only apply to IID data (Central Limit Theorem, T Test, Regression etc)\n",
    "\n",
    "For Non IID Data: \n",
    "\n",
    "1. If Dependent: We need to use methods/models that account for autocorrelation in data (like time-series/clustered models)\n",
    "2. If Heterogeneous: We need to model data from different distributions separately or include covariates (like mixed effects models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0908388c-d98c-4dfb-8767-60a8d631ebde",
   "metadata": {},
   "source": [
    "## Data Storing Guidelines: \n",
    "\n",
    "1. Database software and tools (e.g. SQL) can be very useful for large-scale data management. Some statistical software can read data directly from a database.  Another approach is to construct a text data file from a database e.g. using SQL.\n",
    "2. Hadoop and Spark are two popular tools for manipulating very large datasets.\n",
    "3. HDF5, Apache Parquet, and Apache Arrow are open-source standards for large binary datasets.  Using these formats saves processing time relative to text/csv because fewer conversions are performed when reading and writing the data.\n",
    "4. Large data sets can be saved in compressed form (e.g. using “gzip”) and read into statistical software directly from the compressed file.  This allows the data to be read much faster, and reduces storage space.\n",
    "5. Text/CSV is a better choice than spreadsheet formats (e.g. .xlsx) for data exchange and archiving."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf55d21-ef2b-408e-8142-0a1b9eca0037",
   "metadata": {},
   "source": [
    "## Data Manipulation Software\n",
    "\n",
    "Python has an ecosystem of modules (libraries of code) that augument the base language. A library is a collection of functions and data types that can be accessed without having to implement everything yourself from scratch. \n",
    "\n",
    "Some common libraries useful for statistical analysis are: \n",
    "\n",
    "\n",
    "* **[Pandas](http://pandas.pydata.org)**: A library for efficient and easy-to-use data structures and data analysis tools.\n",
    "\n",
    "* **[Numpy](http://numpy.org)** : A library for working with arrays of data.\n",
    "\n",
    "* **[Scipy](http://scipy.org)**:  A library of techniques for numerical and scientific computing.\n",
    "\n",
    "* **[Statsmodels](http://www.statsmodels.org)**:  A library that implements many statistical techniques.\n",
    "\n",
    "* **[Matplotlib](http://matplotlib.org)**: A library for making graphs.\n",
    "\n",
    "* **[Seaborn](http://seaborn.pydata.org)** A higher-level interface to Matplotlib that can be used to simplify many graphing tasks.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7793fcd-8ed3-48e1-adb9-5e89c2ac1af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(a) = <class 'numpy.ndarray'>\n",
      "\n",
      "a.shape = (3,)\n",
      "type(b) = <class 'numpy.ndarray'>\n",
      "\n",
      "b.shape = (2, 2)\n",
      "c=\n",
      " [[1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "\n",
      "d =\n",
      " [[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Working with Numpy\n",
    "import numpy as np\n",
    "a = np.array([0,1,2,3,4,5,6,7,8,9,10]) # array function from numpy library\n",
    "np.mean(a) # mean function from numpy library\n",
    "\n",
    "#1D array\n",
    "a = np.array([1, 2, 3])\n",
    "print(\"type(a) =\", type(a))\n",
    "print(\"\\na.shape =\", a.shape)\n",
    "\n",
    "\n",
    "#2D Array\n",
    "b = np.array([[1, 2], [3, 4]])\n",
    "print(\"type(b) =\", type(b))\n",
    "print(\"\\nb.shape =\", b.shape)\n",
    "\n",
    "# Array with Shape\n",
    "c=np.ones((2,3))\n",
    "print(\"c=\\n\", c)\n",
    "\n",
    "# Empty Array\n",
    "d=np.empty((2,5))\n",
    "print(\"\\nd =\\n\", d)\n",
    "\n",
    "# Slicing Array\n",
    "h = np.zeros((3, 3))\n",
    "i = h[0:2, 0:2].copy()\n",
    "h[0, 0] = 99\n",
    "print(\"h =\\n\", h)\n",
    "print(\"\\ni =\\n\", i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2445de-8dd1-41f5-8a4e-f46b3d10a130",
   "metadata": {},
   "source": [
    "# Variables/Features\n",
    "\n",
    "The variables in data refer to different aspects of a record on which we have information. Eg: In a typical Census Data, we have a person as a record and corresponding information for variables like age, occupation etc.  There can be different types of variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b60f171-d070-464e-a3cf-e89efd46915b",
   "metadata": {},
   "source": [
    "## Quantitative Variables\n",
    "\n",
    "The value of the feature indicates a numerical quantity that can undergo meaningful mathematical operations. They are primarily of two types: \n",
    "\n",
    "1. Continuous: The feature value can be any number between a fixed interval. Eg: Age, Height, Time, etc\n",
    "2. Discrete: The feature can only take on very specific values. Eg: No of Children.\n",
    "\n",
    "It is often (but not always) the case that discrete data are reperented by the computer with integers, and continuous data are represented by the computer with float values.  In base Python a single \"literal\" number is stored as an integer or as a \"float\" value based on whether it is expressed with a decimal point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b0342ea-e4b3-4af8-a18b-9a2f16ccb051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "<class 'float'>\n",
      "3.5\n",
      "<class 'numpy.float64'>\n",
      "0.6\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# types\n",
    "# integer\n",
    "print(type(4))\n",
    "# base float\n",
    "print(type(4.))\n",
    "# numpy float\n",
    "import numpy as np\n",
    "numbers = np.r_[2, 3, 4, 5]\n",
    "print(type(numbers.mean()))\n",
    "\n",
    "# float vs integer division\n",
    "print(3/5)\n",
    "print(3//5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bf5907-f5ce-40b9-832f-389e2095e37a",
   "metadata": {},
   "source": [
    "## Categorical Variables\n",
    "\n",
    "The value of the feature indicates a classification into different groups and cannot undergo meangful mathematical operations. They are primarily of two types: \n",
    "\n",
    "1. Ordinal: The feature value indicates an order or ranking in groups. Eg: Positions in a Race\n",
    "2. Nominal: The feature value indicates group names. Eg: Football Teams\n",
    "\n",
    "In base Python, Boolean (bool), and String (str) data types are often used to represent nominal values. Ordinal values may be represented by numbers, but it is important to remember that these numbers are codes that do not contain any quantitative information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ac1b01e-acf6-4d3b-b775-a6b6df6befbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bool'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# boolean\n",
    "print(type(True))\n",
    "\n",
    "# string\n",
    "print(type(\"This sentence makes sense\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1de94e3-dc8f-4a84-b6e7-9356426d6108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'NoneType'>\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# None is a special value that is a placeholder representing \"no meaningful value\".\n",
    "# None can be compared using \"is\" or \"==\" but conventionaly \"is\" is preferred\n",
    "print(type(None))\n",
    "print(None is None)\n",
    "print(None == None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8620d90b-44fb-4987-b740-4924e1dcb7ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "statsenv",
   "language": "python",
   "name": "statsenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
